<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>The LEGIT model</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>

<!-- MathJax scripts -->
<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h2>The LEGIT model</h2>

<p>The Latent Environmental &amp; Genetic InTeraction (LEGIT) model is an interaction model with two latent variables: \(\mathbf{g}\) a weighted sum of genetic variants (genetic score) and \(\mathbf{e}\) a weighted sum of environmental variables (environmental score).</p>

<p><img src="https://raw.githubusercontent.com/AlexiaJM/LEGIT/master/images/LEGIT.png" alt=""/></p>

<p>Assuming \(\mathbf{g}_1\),&hellip;,\(\mathbf{g}_k\) are \(k\) genetic variants of interest, generally represented as the number of dominant alleles (0, 1, 2) or the absence or presence of a dominant allele (0, 1) and \(\mathbf{e}_1\),&hellip;,\(\mathbf{e}_s\) are \(s\) environments of interest, generally represented as ordinal scores (0, 1, 2 &hellip;) or continuous variables. We define the genetic score \(\mathbf{g}\) and environmental score \(\mathbf{e}\) as: </p>

<p>\[\mathbf{g}=\sum_{i=1}^{k} p_i \mathbf{g}_j \] 
\[\mathbf{e}=\sum_{l=1}^{s} q_l \mathbf{e}_l \]
where \(\|p\|_1=\sum_{i=1}^{k}p_j=1\) and \(\|q\|_1= \sum_{l=1}^{s}q_l=1\). The weights can be interpreted as the relative contributions of each genetic variant or environment.</p>

<p>The weights of these scores are estimated within a generalized linear model of the form :</p>

<p>\[\mathbf{E}[\mathbf{y}] = g^{-1}(f(\mathbf{g},\mathbf{e},X|\beta)+X_{covs} \beta_{covs})\]
where \(g\) is the link function, \(f\) is a linear function between \(\mathbf{g}\), \(\mathbf{e}\) and other variables from the matrix \(X\) and \(X_{covs}\) is a matrix of additionnal covariates.</p>

<p>Although this approach was originally made for GxE modelling, it is flexible and does not require the use of genetic and environmental variables. It can also handle more than 2 latent variables (rather than just G and E) and 3-way interactions or more.</p>

<p>For a two-way \(G\times E\) model, we would define \(f\) as:</p>

<p>\[f(\mathbf{g},\mathbf{e},X|\beta) = \beta_0+\beta_e \mathbf{e}+\beta_g \mathbf{g}+\beta_{eg} \mathbf{e}\mathbf{g}\]</p>

<p>For a three-way \(G\times E \times Z\) model, we would define \(f\) as:</p>

<p>\[f(\mathbf{g},\mathbf{e},X|\beta) = \beta_0+\beta_e \mathbf{e}+\beta_g \mathbf{g}+\beta_z \mathbf{z}+\beta_{eg} \mathbf{eg}+\beta_{ez} \mathbf{ez}+\beta_{zg} \mathbf{zg}+\beta_{egz} \mathbf{egz}\]</p>

<h2>Examples of LEGIT models</h2>

<p>Here is an example with 2 latent variables and a 2-way interaction (see <a href="arxiv.org/abs/1703.08111">arxiv</a>) :
<img src="https://raw.githubusercontent.com/AlexiaJM/LEGIT/master/images/LEGIT_2way.png" alt=""/></p>

<p>Here is an example with 3 latent variables and a 3-way interaction (see <a href="arxiv.org/abs/1703.08111">arxiv</a>) :
<img src="https://raw.githubusercontent.com/AlexiaJM/LEGIT/master/images/LEGIT_3way.png" alt=""/></p>

<h2>Algorithm</h2>

<p>Full details of the algorithm are available on <a href="arxiv.org/abs/1703.08111">arXiv</a>.</p>

<h2>Implementation</h2>

<p>In the LEGIT package, we include the following functions:</p>

<p>To fit a LEGIT model with 2 latent variables (G and E)</p>

<ul>
<li>LEGIT: Fits a LEGIT model</li>
<li>plot.LEGIT: Plot function for LEGIT models.</li>
<li>predict.LEGIT: Predictions of LEGIT fits.</li>
<li>summary.LEGIT: Summarizing LEGIT fits.</li>
<li>LEGIT_cv: Uses cross-validation on a LEGIT model.</li>
<li>stepwise_search: Adds the best variable or drops the worst variable one at a time in the genetic or environmental score of a LEGIT model.</li>
<li>GxE_interaction_test: Testing of the GxE interaction, a method adapted from Belsky, Pluess et Widaman (2013). Reports the different hypotheses (diathesis-stress/vantage-sensitivity vs differential susceptibility), assuming or not assuming a main effect for E (WEAK vs STRONG) using the LEGIT model.</li>
</ul>

<p>To fit a IMLEGIT model (LEGIT model with more than 2 latent variables)</p>

<ul>
<li>IMLEGIT: Fits a IMLEGIT model.</li>
<li>predict.IMLEGIT: Predictions of IMLEGIT fits.</li>
<li>summary.IMLEGIT: Summarizing IMLEGIT fits.</li>
<li>IMLEGIT_cv: Uses cross-validation on a IMLEGIT model.</li>
<li>stepwise_search_IM: Adds the best variable or drops the worst variable one at a time in the genetic or environmental score of a IMLEGIT model.</li>
<li>bootstrap_var_select: Creates bootstrap samples, run stepwise search on all of them and then report the percentage of times that each variables were selected.</li>
<li>genetic_var_select: Parallel genetic algorithm variable selection.</li>
</ul>

<p>To simulate examples of GxE models</p>

<ul>
<li>example_2way: Simulated example of a 2 way interaction GxE model (where G and E are latent variables).</li>
<li>example_3way: Simulated example of a 3 way interaction GxExz model (where G and E are latent variables).</li>
<li>example_3way_3latent: Simulated example of a 3 way interaction GxExZ model (where G, E and Z are latent variables).</li>
<li>example_with_crossover: Simulated example of a 2 way interaction GxE model with cross-over point (where G and E are latent variables).</li>
</ul>

<p>Others</p>

<ul>
<li>longitudinal_folds: Function to create folds adequately for longitudinal datasets by forcing every observation with the same id to be in the same fold. Can be used with LEGIT_cv to make sure that the cross-validation folds are appropriate when using longitudinal data.</li>
</ul>

<h2>Notes</h2>

<ul>
<li>Interactions inside the genetic and environmental scores must be manually coded as new variables (ex: g1, g2, g1_g2 where g1_g2=g1*g2).</li>
<li>Default starting point is set to \(1/k\) for each of the genetic variants and \(1/s\) for each of the environmental variables.</li>
<li>Only local convergence is guaranteed, therefore it is recommended to try different starting points. </li>
</ul>

<h2>How to use the LEGIT package: Example 1</h2>

<p>Let&#39;s look at a three-way interaction model with continuous outcome:</p>

<p>\[\mathbf{g}_j \sim Binomial(n=1,p=.30) \ j = 1, 2, 3, 4\]
\[\mathbf{e}_l \sim Normal(\mu=0,\sigma=1.5) \ l = 1, 2, 3\]
\[\mathbf{z} \sim Normal(\mu=3,\sigma=1)\]
\[\mathbf{g} = .2\mathbf{g}_1 + .15\mathbf{g}_2 - .3\mathbf{g}_3 + .1\mathbf{g}_4 + .05\mathbf{g}_1\mathbf{g}_3 + .2\mathbf{g}_2\mathbf{g}_3 \]
\[ \mathbf{e} = -.45\mathbf{e}_1 + .35\mathbf{e}_2 + .2\mathbf{e}_3\]
\[\mathbf{\mu} = -2 + 2\mathbf{g} + 3\mathbf{e} + \mathbf{z} + 5\mathbf{ge} + 2\mathbf{gz} - 1.5\mathbf{ez} + 2\mathbf{gez} \] 
\[ y \sim Normal(\mu,\sigma=1)\]</p>

<p>Let&#39;s load the package and look at the dataset.</p>

<pre><code class="r">library(LEGIT)
example_3way(N=5, sigma=1, logit=FALSE, seed=7)
</code></pre>

<pre><code>## $data
##             y     y_true        z
## 1  3.80723699 4.67808801 3.184193
## 2  7.96819988 7.24948932 3.752280
## 3  4.49051121 4.37985833 3.591745
## 4 -0.01796159 0.06050518 2.016947
## 5  0.71520307 1.13569353 2.723936
## 
## $G
##   g1 g2 g3 g4 g1_g3 g2_g3
## 1  1  1  0  0     0     0
## 2  0  0  0  0     0     0
## 3  0  1  1  0     0     1
## 4  0  0  0  1     0     0
## 5  0  0  0  0     0     0
## 
## $E
##          e1           e2        e3
## 1 0.5354793  0.701520767  1.259626
## 2 4.0751277 -1.340701085  1.058013
## 3 3.4221779 -0.460992449  1.958947
## 4 0.4860308 -0.007233633 -2.081994
## 5 2.8441006  1.482246224  1.909375
## 
## $coef_G
## [1]  0.20  0.15 -0.30  0.10  0.05  0.20
## 
## $coef_E
## [1] -0.45  0.35  0.20
## 
## $coef_main
## [1] -2.0  2.0  3.0  1.0  5.0 -1.5  2.0  2.0
</code></pre>

<p>Currently &ldquo;data&rdquo; contains the outcome, the true outcome without the noise and the covariate \(z\). This dataset should always contain the outcome and all covariates (except for the genes and environments from \(\mathbf{g}\) and \(\mathbf{e}\)).&ldquo;G&rdquo; contains the genetic variants and &ldquo;E&rdquo; contains the environments. This is all you need to fit a LEGIT model.</p>

<p>We generate N=250 training observations and 100 test observations.</p>

<pre><code class="r">train = example_3way(N=250, sigma=1, logit=FALSE, seed=7)
test = example_3way(N=100, sigma=1, logit=FALSE, seed=6)
</code></pre>

<p>We fit the model with the default starting point.</p>

<pre><code class="r">fit_default = LEGIT(train$data, train$G, train$E, y ~ G*E*z)
</code></pre>

<pre><code>## Converged in 11 iterations
</code></pre>

<pre><code class="r">summary(fit_default)
</code></pre>

<pre><code>## $fit_main
## 
## Call:
## stats::glm(formula = formula, family = family, data = data, model = FALSE, 
##     y = FALSE)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.94965  -0.62453   0.08363   0.62145   2.65154  
## 
## Coefficients: (-7 not defined because of singularities)
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.77075    0.22342  -7.926 9.09e-14 ***
## G            0.15934    1.12858   0.141    0.888    
## E           -2.86208    0.27217 -10.516  &lt; 2e-16 ***
## z            0.94193    0.06704  14.050  &lt; 2e-16 ***
## G:E         -5.69624    1.38253  -4.120 5.25e-05 ***
## G:z          2.61973    0.34190   7.662 4.77e-13 ***
## E:z          1.43411    0.07991  17.947  &lt; 2e-16 ***
## G:E:z       -1.82548    0.41205  -4.430 1.44e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 1.065046)
## 
##     Null deviance: 2414.03  on 249  degrees of freedom
## Residual deviance:  250.29  on 235  degrees of freedom
## AIC: 741.75
## 
## Number of Fisher Scoring iterations: 2
## 
## 
## $fit_genes
## 
## Call:
## stats::glm(formula = formula_b, family = family, data = data, 
##     model = FALSE, y = FALSE)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.95636  -0.63173   0.07961   0.62078   2.65154  
## 
## Coefficients: (-9 not defined because of singularities)
##       Estimate Std. Error t value Pr(&gt;|t|)    
## g1     0.18333    0.01051  17.447  &lt; 2e-16 ***
## g2     0.15867    0.01422  11.156  &lt; 2e-16 ***
## g3    -0.29336    0.01269 -23.115  &lt; 2e-16 ***
## g4     0.09770    0.01090   8.966  &lt; 2e-16 ***
## g1_g3  0.06273    0.02247   2.791  0.00568 ** 
## g2_g3  0.20421    0.02329   8.770 3.68e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 1.06503)
## 
##     Null deviance: 2414.03  on 250  degrees of freedom
## Residual deviance:  250.28  on 235  degrees of freedom
## AIC: 741.75
## 
## Number of Fisher Scoring iterations: 2
## 
## 
## $fit_env
## 
## Call:
## stats::glm(formula = formula_c, family = family, data = data, 
##     model = FALSE, y = FALSE)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.94953  -0.62434   0.08404   0.62125   2.65128  
## 
## Coefficients: (-12 not defined because of singularities)
##    Estimate Std. Error t value Pr(&gt;|t|)    
## e1  0.43440    0.01486   29.24   &lt;2e-16 ***
## e2 -0.35307    0.01756  -20.11   &lt;2e-16 ***
## e3 -0.21253    0.01614  -13.17   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 1.065045)
## 
##     Null deviance: 2414.03  on 250  degrees of freedom
## Residual deviance:  250.29  on 235  degrees of freedom
## AIC: 741.75
## 
## Number of Fisher Scoring iterations: 2
</code></pre>

<p>This is very close to the original model. We can now use the test dataset to find the validation \(R^2\).</p>

<pre><code class="r">ssres = sum((test$data$y - predict(fit_default, test$data, test$G, test$E))^2)
sstotal = sum((test$data$y - mean(test$data$y))^2)
R2 = 1 - ssres/sstotal
R2
</code></pre>

<pre><code>## [1] 0.8809351
</code></pre>

<p>We can also plot the model at specific values of z.</p>

<pre><code class="r">cov_values = c(3)
names(cov_values) = &quot;z&quot;
plot(fit_default, cov_values = cov_values,cex.leg=1.4, cex.axis=1.5, cex.lab=1.5)
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk fig3"/></p>

<p>Now, let&#39;s see what happens if we introduce variables that are not in the model. Let&#39;s add these irrelevant genetic variants:</p>

<p>\[\mathbf{g'}_b \sim Binomial(n=1,p=.30) \ b = 1, 2, 3, 4, 5\]</p>

<pre><code class="r">g1_bad = rbinom(250,1,.30)
g2_bad = rbinom(250,1,.30)
g3_bad = rbinom(250,1,.30)
g4_bad = rbinom(250,1,.30)
g5_bad = rbinom(250,1,.30)
train$G = cbind(train$G, g1_bad, g2_bad, g3_bad, g4_bad, g5_bad)
</code></pre>

<p>Let&#39;s do a forward search of the genetic variants using the BIC and see if we can recover the right subset of variables.</p>

<pre><code class="r">forward_genes_BIC = stepwise_search(train$data, genes_extra=train$G, env_original=train$E, formula=y ~ E*G*z, search_type=&quot;forward&quot;, search=&quot;genes&quot;, search_criterion=&quot;BIC&quot;, interactive_mode=FALSE)
</code></pre>

<pre><code>## Keeping only variables with p-values smaller than 0.2 and which inclusion decrease the AIC
## Forward search of the genes to find the model with the lowest BIC
## 
## [Iteration: 1]
## Adding gene: g3 (Criterion before = Inf; after = 1125.42059)
## [Iteration: 2]
## Adding gene: g2 (Criterion before = 1125.42059; after = 1042.75045)
## [Iteration: 3]
## Adding gene: g1 (Criterion before = 1042.75045; after = 888.44286)
## [Iteration: 4]
## Adding gene: g4 (Criterion before = 888.44286; after = 846.44854)
## [Iteration: 5]
## Adding gene: g2_g3 (Criterion before = 846.44854; after = 799.55835)
## [Iteration: 6]
## Adding gene: g1_g3 (Criterion before = 799.55835; after = 798.62631)
## [Iteration: 7]
## No gene added
</code></pre>

<p>We recovered the right subset! Now what if we did a backward search using the AIC?</p>

<pre><code class="r">backward_genes_AIC = stepwise_search(train$data, genes_original=train$G, env_original=train$E, formula=y ~ E*G*z, search_type=&quot;backward&quot;, search=&quot;genes&quot;, search_criterion=&quot;AIC&quot;, interactive_mode=FALSE)
</code></pre>

<pre><code>## Dropping only variables with p-values bigger than 0.01 and which removal decrease the AIC
## Backward search of the genes to find the model with the lowest AIC
## 
## [Iteration: 1]
## Removing gene: g3_bad (Criterion before = 749.77592; after = 747.50098)
## [Iteration: 2]
## Removing gene: g5_bad (Criterion before = 747.50098; after = 745.40215)
## [Iteration: 3]
## Removing gene: g4_bad (Criterion before = 745.40215; after = 743.57487)
## [Iteration: 4]
## Removing gene: g1_bad (Criterion before = 743.57487; after = 741.8472)
## [Iteration: 5]
## Removing gene: g2_bad (Criterion before = 741.8472; after = 741.75015)
## [Iteration: 6]
## No gene removed
</code></pre>

<p>We deleted the irrevelant genes and obtained the right subset of variables! The stepwise_search function also has an interactive mode where the user decides which variable should be added/dropped at every step. We can only show the first iteration because the algorithm does&#39;nt receive an input from the user in the vignette but normally you can control the variables added or removed from the stepwise search. This is what the interactive mode looks like:</p>

<pre><code class="r">forward_genes_BIC = stepwise_search(train$data, genes_extra=train$G, env_original=train$E, formula=y ~ E*G*z, search_type=&quot;bidirectional-forward&quot;, search=&quot;genes&quot;, search_criterion=&quot;BIC&quot;, interactive_mode=TRUE)
</code></pre>

<pre><code>## &lt;&lt;~ Interative mode enabled ~&gt;&gt;
## Keeping only variables with p-values smaller than 0.2 and which inclusion decrease the AIC
## Dropping only variables with p-values bigger than 0.01 and which removal decrease the AIC
## Bidirectional search of the genes to find the model with the lowest BIC
## 
## [Iteration: 1]
##   variable N_old N_new p_value AIC_old  AIC_new AICc_old AICc_new BIC_old
## 1       g3    NA   250 0.00000     Inf 1086.685      Inf 1087.794     Inf
## 2       g1    NA   250 0.00000     Inf 1093.552      Inf 1094.661     Inf
## 3       g2    NA   250 0.00000     Inf 1135.100      Inf 1136.209     Inf
## 4   g1_bad    NA   250 0.00000     Inf 1155.719      Inf 1156.828     Inf
## 5       g4    NA   250 0.00013     Inf 1164.285      Inf 1165.394     Inf
##    BIC_new
## 1 1125.421
## 2 1132.288
## 3 1173.836
## 4 1194.455
## 5 1203.021
## Enter the index of the gene to be added: 
## No gene added
</code></pre>

<p>Manually forcing \(\mathbf{g}_3\) inclusion since the interactive mode cannot progress without a user, we get that the second iteration is:</p>

<pre><code class="r">forward_genes_BIC = stepwise_search(train$data, genes_original=train$G[,3,drop=FALSE], genes_extra=train$G[,-3], env_original=train$E, formula=y ~ E*G*z, search_type=&quot;bidirectional-forward&quot;, search=&quot;genes&quot;, search_criterion=&quot;BIC&quot;, interactive_mode=TRUE)
</code></pre>

<pre><code>## &lt;&lt;~ Interative mode enabled ~&gt;&gt;
## Keeping only variables with p-values smaller than 0.2 and which inclusion decrease the AIC
## Dropping only variables with p-values bigger than 0.01 and which removal decrease the AIC
## Bidirectional search of the genes to find the model with the lowest BIC
## 
## [Iteration: 1]
##   variable N_old N_new  p_value  AIC_old  AIC_new AICc_old AICc_new
## 1       g2   250   250 0.000000 1086.685 1000.493 1087.794 1001.809
## 2    g2_g3   250   250 0.000000 1086.685 1006.253 1087.794 1007.570
## 3       g1   250   250 0.000000 1086.685 1013.285 1087.794 1014.601
## 4    g1_g3   250   250 0.000002 1086.685 1068.051 1087.794 1069.367
## 5       g4   250   250 0.012411 1086.685 1084.133 1087.794 1085.450
##    BIC_old  BIC_new
## 1 1125.421 1042.750
## 2 1125.421 1048.511
## 3 1125.421 1055.542
## 4 1125.421 1110.308
## 5 1125.421 1126.391
## Enter the index of the gene to be added: 
## No gene added
</code></pre>

<p>With the interactive mode, you can try alternative pathways, rather than simply adding/dropping the best/worst variable everytime.</p>

<h2>How to use the LEGIT package: Example 2</h2>

<p>Let&#39;s take a quick look at a simple two-way example with binary outcome:</p>

<p>\[\mathbf{g}_j \sim Binomial(n=1,p=.30) \ j = 1, 2, 3, 4\]
\[\mathbf{e}_l \sim Normal(\mu=0,\sigma=1.5) \ l = 1, 2, 3\]
\[\mathbf{g} = .2\mathbf{g}_1 + .15\mathbf{g}_2 - .3\mathbf{g}_3 + .1\mathbf{g}_4 + .05\mathbf{g}_1\mathbf{g}_3 + .2\mathbf{g}_2\mathbf{g}_3 \] 
\[ \mathbf{e} = -.45\mathbf{e}_1 + .35\mathbf{e}_2 + .2\mathbf{e}_3\]
\[\mathbf{\mu} = -1 + 2\mathbf{g} + 3\mathbf{e} + 4\mathbf{ge} \]
\[ y \sim Binomial(n=1,p=logit(\mu))\]</p>

<p>We generate N=1000 training observations.</p>

<pre><code class="r">library(LEGIT)
train = example_2way(N=1000, logit=TRUE, seed=777)
</code></pre>

<p>We fit the model with the default starting point.</p>

<pre><code class="r">fit_default = LEGIT(train$data, train$G, train$E, y ~ G*E, family=binomial)
</code></pre>

<pre><code>## Converged in 6 iterations
</code></pre>

<pre><code class="r">summary(fit_default)
</code></pre>

<pre><code>## $fit_main
## 
## Call:
## stats::glm(formula = formula, family = family, data = data, model = FALSE, 
##     y = FALSE)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.2401  -0.5533  -0.1316   0.4363   3.0637  
## 
## Coefficients: (-7 not defined because of singularities)
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -0.9892     0.1065  -9.293  &lt; 2e-16 ***
## G             2.0863     0.6747   3.092 0.001989 ** 
## E             3.2313     0.2148  15.042  &lt; 2e-16 ***
## G:E           4.3265     1.1960   3.617 0.000298 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1351.50  on 999  degrees of freedom
## Residual deviance:  692.69  on 989  degrees of freedom
## AIC: 714.69
## 
## Number of Fisher Scoring iterations: 6
## 
## 
## $fit_genes
## 
## Call:
## stats::glm(formula = formula_b, family = family, data = data, 
##     model = FALSE, y = FALSE)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.3976  -0.5512  -0.1208   0.4385   3.0640  
## 
## Coefficients: (-5 not defined because of singularities)
##       Estimate Std. Error z value Pr(&gt;|z|)    
## g1     0.12059    0.07512   1.605  0.10842    
## g2     0.08314    0.06927   1.200  0.23005    
## g3    -0.28041    0.05142  -5.454 4.94e-08 ***
## g4     0.02208    0.05359   0.412  0.68030    
## g1_g3  0.06894    0.12845   0.537  0.59146    
## g2_g3  0.42484    0.15154   2.804  0.00505 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1351.50  on 1000  degrees of freedom
## Residual deviance:  692.69  on  989  degrees of freedom
## AIC: 714.69
## 
## Number of Fisher Scoring iterations: 6
## 
## 
## $fit_env
## 
## Call:
## stats::glm(formula = formula_c, family = family, data = data, 
##     model = FALSE, y = FALSE)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.3965  -0.5513  -0.1277   0.4389   3.0637  
## 
## Coefficients: (-8 not defined because of singularities)
##    Estimate Std. Error z value Pr(&gt;|z|)    
## e1 -0.43085    0.02905 -14.832   &lt;2e-16 ***
## e2  0.35751    0.02613  13.681   &lt;2e-16 ***
## e3  0.21164    0.02156   9.814   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1351.50  on 1000  degrees of freedom
## Residual deviance:  692.69  on  989  degrees of freedom
## AIC: 714.69
## 
## Number of Fisher Scoring iterations: 6
</code></pre>

<p>We are a little off, especially with regards to the weights of the genetic variants. This is because there is substantial loss of information with binary outcomes. To assess the quality of the fit, we are going to do a 5-Folds cross-validation.</p>

<pre><code class="r">cv_5folds_bin = LEGIT_cv(train$data, train$G, train$E, y ~ G*E, cv_iter=1, cv_folds=5, classification=TRUE, family=binomial, seed=777)
pROC::plot.roc(cv_5folds_bin$roc_curve[[1]])
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk fig1"/></p>

<p>Although the weights of the genetic variants are a bit off, the model predictive power is good.</p>

<p>We can also plot the model.</p>

<pre><code class="r">plot(fit_default, cex.leg=1.4, cex.axis=1.5, cex.lab=1.5)
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk fig2"/></p>

<h2>How to use the LEGIT package: Example 3</h2>

<p>In example 1 we looked at a 3-way model but only two of the three variables were latent. Let&#39;s construct the model another time but this time with three latent variables:</p>

<p>\[\mathbf{g}_j \sim Binomial(n=1,p=.30) \ j = 1, 2, 3, 4\]
\[\mathbf{e}_l \sim Normal(\mu=0,\sigma=1.5) \ l = 1, 2, 3\]
\[\mathbf{z}_t \sim Normal(\mu=3,\sigma=1)\]
\[\mathbf{g} = .2\mathbf{g}_1 + .15\mathbf{g}_2 - .3\mathbf{g}_3 + .1\mathbf{g}_4 + .05\mathbf{g}_1\mathbf{g}_3 + .2\mathbf{g}_2\mathbf{g}_3 \]
\[ \mathbf{e} = -.45\mathbf{e}_1 + .35\mathbf{e}_2 + .2\mathbf{e}_3\]
\[ \mathbf{z} = .15\mathbf{z}_1 + .60\mathbf{z}_2 + .25\mathbf{z}_3\]
\[\mathbf{\mu} = -2 + 2\mathbf{g} + 3\mathbf{e} + \mathbf{z} + 5\mathbf{ge} + 2\mathbf{gz} - 1.5\mathbf{ez} + 2\mathbf{gez} \] 
\[ y \sim Normal(\mu,\sigma=1)\]</p>

<p>Let&#39;s load the package and look at the dataset.</p>

<pre><code class="r">library(LEGIT)
example_3way_3latent(N=5, sigma=1, logit=FALSE, seed=7)
</code></pre>

<pre><code>## $data
##           y   y_true
## 1 4.6022635 3.383713
## 2 6.5474680 7.246785
## 3 2.5382622 2.823695
## 4 0.2960498 1.607602
## 5 0.6674754 1.058488
## 
## $latent_var
## $latent_var$G
##   g1 g2 g3 g4 g1_g3 g2_g3
## 1  1  1  0  0     0     0
## 2  0  0  0  0     0     0
## 3  0  1  1  0     0     1
## 4  0  0  0  1     0     0
## 5  0  0  0  0     0     0
## 
## $latent_var$E
##          e1           e2        e3
## 1 0.5354793  0.701520767  1.259626
## 2 4.0751277 -1.340701085  1.058013
## 3 3.4221779 -0.460992449  1.958947
## 4 0.4860308 -0.007233633 -2.081994
## 5 2.8441006  1.482246224  1.909375
## 
## $latent_var$Z
##         z1       z2       z3
## 1 3.184193 2.129149 2.437874
## 2 3.752280 3.718711 3.997513
## 3 3.591745 3.110653 1.894870
## 4 2.016947 2.921533 2.857712
## 5 2.723936 2.579510 3.314995
## 
## 
## $coef_G
## [1]  0.20  0.15 -0.30  0.10  0.05  0.20
## 
## $coef_E
## [1] -0.45  0.35  0.20
## 
## $coef_Z
## [1] 0.15 0.75 0.10
## 
## $coef_main
## [1] -2.0  2.0  3.0  1.0  5.0 -1.5  2.0  2.0
</code></pre>

<p>Currently &ldquo;data&rdquo; contains the outcome and the true outcome without the noise. This dataset should always contain the outcome and all covariates not included in latent_var.The latent variables are called &ldquo;G&rdquo;, &ldquo;E&rdquo; and &ldquo;Z&rdquo; respectively.</p>

<p>We generate N=250 training observations.</p>

<pre><code class="r">train = example_3way_3latent(N=250, sigma=1, logit=FALSE, seed=7)
</code></pre>

<p>We fit the model with the default starting point.</p>

<pre><code class="r">fit_default = IMLEGIT(train$data, train$latent_var, y ~ G*E*Z)
</code></pre>

<pre><code>## Converged in 9 iterations
</code></pre>

<pre><code class="r">summary(fit_default)
</code></pre>

<pre><code>## $fit_main
## 
## Call:
## stats::glm(formula = formula, family = family, data = data, model = FALSE, 
##     y = FALSE)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.83950  -0.61829  -0.06514   0.63174   2.94218  
## 
## Coefficients: (-9 not defined because of singularities)
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.73742    0.28854  -6.021 6.67e-09 ***
## G            3.69821    1.44085   2.567 0.010894 *  
## E           -2.88702    0.35440  -8.146 2.29e-14 ***
## Z            0.93184    0.09084  10.258  &lt; 2e-16 ***
## G:E         -6.43857    1.73999  -3.700 0.000269 ***
## G:Z          1.50043    0.45407   3.304 0.001102 ** 
## E:Z          1.41024    0.11155  12.643  &lt; 2e-16 ***
## G:E:Z       -1.87914    0.56505  -3.326 0.001025 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 1.072187)
## 
##     Null deviance: 2042.53  on 249  degrees of freedom
## Residual deviance:  249.82  on 233  degrees of freedom
## AIC: 745.29
## 
## Number of Fisher Scoring iterations: 2
## 
## 
## $fit_G
## 
## Call:
## stats::glm(formula = formula_step[[i]], family = family, data = data, 
##     model = FALSE, y = FALSE)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.83926  -0.62150  -0.06564   0.62966   2.94218  
## 
## Coefficients: (-11 not defined because of singularities)
##       Estimate Std. Error t value Pr(&gt;|t|)    
## g1     0.18509    0.01039  17.806  &lt; 2e-16 ***
## g2     0.13924    0.01288  10.808  &lt; 2e-16 ***
## g3    -0.30681    0.01308 -23.456  &lt; 2e-16 ***
## g4     0.09764    0.01067   9.154  &lt; 2e-16 ***
## g1_g3  0.06429    0.02208   2.912  0.00394 ** 
## g2_g3  0.20693    0.02253   9.184  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 1.072171)
## 
##     Null deviance: 2042.53  on 250  degrees of freedom
## Residual deviance:  249.82  on 233  degrees of freedom
## AIC: 745.29
## 
## Number of Fisher Scoring iterations: 2
## 
## 
## $fit_E
## 
## Call:
## stats::glm(formula = formula_step[[i]], family = family, data = data, 
##     model = FALSE, y = FALSE)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.83891  -0.62160  -0.06617   0.62772   2.94215  
## 
## Coefficients: (-14 not defined because of singularities)
##    Estimate Std. Error t value Pr(&gt;|t|)    
## e1  0.46366    0.01715   27.04   &lt;2e-16 ***
## e2 -0.36535    0.01861  -19.63   &lt;2e-16 ***
## e3 -0.17098    0.01612  -10.61   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 1.072175)
## 
##     Null deviance: 2042.53  on 250  degrees of freedom
## Residual deviance:  249.82  on 233  degrees of freedom
## AIC: 745.29
## 
## Number of Fisher Scoring iterations: 2
## 
## 
## $fit_Z
## 
## Call:
## stats::glm(formula = formula_step[[i]], family = family, data = data, 
##     model = FALSE, y = FALSE)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.83969  -0.62113  -0.06676   0.62714   2.94173  
## 
## Coefficients: (-14 not defined because of singularities)
##    Estimate Std. Error t value Pr(&gt;|t|)    
## z1  0.11464    0.03060   3.747 0.000226 ***
## z2  0.73843    0.03279  22.522  &lt; 2e-16 ***
## z3  0.14692    0.03185   4.613 6.56e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 1.072175)
## 
##     Null deviance: 2042.53  on 250  degrees of freedom
## Residual deviance:  249.82  on 233  degrees of freedom
## AIC: 745.29
## 
## Number of Fisher Scoring iterations: 2
</code></pre>

<p>Let&#39;s add irrelevant genes and try a forward search as before. Note that search = 1 means that we will search for the first latent variable which is &ldquo;G&rdquo;. We could also set search = 0 to search through all latent variables.</p>

<p>\[\mathbf{g'}_b \sim Binomial(n=1,p=.30) \ b = 1, 2, 3, 4, 5\]</p>

<pre><code class="r">g1_bad = rbinom(250,1,.30)
g2_bad = rbinom(250,1,.30)
g3_bad = rbinom(250,1,.30)
g4_bad = rbinom(250,1,.30)
g5_bad = rbinom(250,1,.30)
G_new = cbind(train$G, g1_bad, g2_bad, g3_bad, g4_bad, g5_bad)
forward_genes_BIC = stepwise_search_IM(train$data, latent_var_original=train$latent_var, latent_var_extra=list(G=G_new, E=NULL, Z=NULL), formula=y ~ E*G*Z, search_type=&quot;forward&quot;, search=1, search_criterion=&quot;BIC&quot;, interactive_mode=FALSE)
</code></pre>

<pre><code>## Keeping only variables with p-values smaller than 0.2 and which inclusion decrease the AIC
## Forward search of the elements from G to find the model with the lowest BIC
## 
## [Iteration: 1]
## No element from G was added
</code></pre>

<p>We didn&#39;t add any irrelevant genes.</p>

</body>

</html>
